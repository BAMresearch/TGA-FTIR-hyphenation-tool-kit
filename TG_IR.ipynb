{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TG_IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running, you have to supply a 'home' path (location of notebook) and a 'dir_data' path (location of raw data) in the first cell.\n",
    "#### The program assumes a predefined directory structure that contains the supplied files:\n",
    "\n",
    "+ **'home'**\n",
    "    + *TG_IR.ipynb*\n",
    "    + **Kali**\n",
    "        + *cali.xlsx*\n",
    "    + **Fitting**\n",
    "    + **Sample_Listen**\n",
    "    + **Parameter**\n",
    "        + *labels.xlsx*\n",
    "        + *surfgr_C.xlsx*\n",
    "    + **Output**\n",
    "        + **Plots**\n",
    "\n",
    "Legend:\n",
    "**directory**,*file*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as grid\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rcParams['figure.figsize'] = 15,7.5\n",
    "\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.optimize import curve_fit, minimize\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import datetime as dt\n",
    "import pickle\n",
    "\n",
    "import copy\n",
    "import re\n",
    "\n",
    "#directories for loading and saving of data\n",
    "home=os.path.abspath('')#<<----------------------------------------\n",
    "dir_data=os.path.abspath('')#<<----------------------------------------\n",
    "dir_cali=os.path.join(home,'Kali')\n",
    "dir_fits=os.path.join(home,'Fitting')\n",
    "dir_samples=os.path.join(home,'Sample_Listen')\n",
    "dir_parameters=os.path.join(home,'Parameter')\n",
    "dir_output=os.path.join(home,'Output')\n",
    "dir_plots=os.path.join(dir_output,'Plots')\n",
    "os.chdir(home)\n",
    "        \n",
    "#plotlabels\n",
    "inp=pd.read_excel(os.path.join(dir_parameters,'labels.xlsx'),sheet_name=['samples','gases','plots'],index_col=0)\n",
    "LABELS=dict(zip(inp['samples'].index,inp['samples']['label']))\n",
    "LABELS.update(dict(zip(inp['gases'].index,inp['gases']['label'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(key):\n",
    "    if key in LABELS:\n",
    "        return LABELS[key]\n",
    "    try:\n",
    "        if int(key)in LABELS:\n",
    "            return LABELS[int(key)]\n",
    "    except:\n",
    "        return str(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time():\n",
    "    return str(dt.datetime.now().date())+'_'+str(dt.datetime.now().hour)+'-'+str(dt.datetime.now().minute).zfill(2)+'-'+str(dt.datetime.now().second).zfill(2)+'_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_path(file,parent_dir):\n",
    "    for dirpath,dirnames,filenames in os.walk(parent_dir):\n",
    "        for filename in filenames:\n",
    "            if filename[:filename.rfind('.')].find(file)!=-1:\n",
    "                return dirpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_files(file,suffix,parent_dir):\n",
    "    files=[]\n",
    "    for dirpath,dirnames,filenames in os.walk(parent_dir):\n",
    "        for filename in filenames:\n",
    "            if (re.search(re.escape(file),filename)!=None) and (re.search(suffix+'$',filename,flags=re.IGNORECASE)):\n",
    "                files.append(os.path.join(dirpath,filename))   \n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "```plot_TGA``` takes TGA-data and plots the sample mass against the sample temperature.\n",
    "\n",
    "```plot_FTIR``` takes the FTIR-data and plots the absorbance of each gas over the time.\n",
    "\n",
    "```FTIR_to_DTG``` reconstructs the DTG from the gas release and compares it to the DTG from TGA.\n",
    "\n",
    "```plot_gauss```  takes lists of parameters of the normal distribution and plots the distributions seperately in the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_TGA(TG_IR,plot,save=False,x_axis='Ts',y_axis='orig'):\n",
    "    fig, TGA=plt.subplots()\n",
    "    \n",
    "    fig.subplots_adjust(right=.8)\n",
    "    \n",
    "    DTG=TGA.twinx()\n",
    "    \n",
    "    x=TG_IR.tga[x_axis]\n",
    "    if y_axis=='rel':\n",
    "        y=(TG_IR.tga[plot]/TG_IR.tga['mass'][0])*100\n",
    "        yDTG=TG_IR.tga['dtg']*60/TG_IR.tga['mass'][0]\n",
    "        ylabelDTG=r'DTG /% $min^{-1}$'\n",
    "        if plot=='mass':\n",
    "            ylabel='mass /%'\n",
    "        elif plot=='heat_flow':\n",
    "            ylabel='heat flow  $/mW mg^{-1}$'\n",
    "        \n",
    "    elif y_axis=='orig':\n",
    "        y=TG_IR.tga[plot]\n",
    "        yDTG=TG_IR.tga['dtg']*60\n",
    "        ylabelDTG='DTG $/mg min^{-1}$'\n",
    "        if plot=='mass':\n",
    "            ylabel='mass /mg'\n",
    "        elif plot=='heat_flow':\n",
    "            ylabel='heat flow /mW'\n",
    "\n",
    "    if x_axis=='Ts':\n",
    "        TGA.set_xlabel('T /째C')\n",
    "    elif x_axis=='t':\n",
    "        x=x/60\n",
    "        TGA.set_xlabel('t /min')\n",
    "        temp=TGA.twinx()\n",
    "        temp.plot(x,TG_IR.tga['Ts'],label='T /째C',ls='dashed',color='black')\n",
    "        temp.spines['right'].set_position(('axes',1.15))\n",
    "        temp.set_ylabel('T /째C')\n",
    "        temp.legend(loc=1)\n",
    "        \n",
    "    gTGA,=TGA.plot(x,y,'r-',label=ylabel)\n",
    "    gDTG,=DTG.plot(x,yDTG,'b--',label='DTG')\n",
    "    \n",
    "    TGA.set_ylabel(ylabel)\n",
    "    DTG.set_ylabel(ylabelDTG)\n",
    "        \n",
    "    TGA.yaxis.label.set_color(gTGA.get_color())\n",
    "    DTG.yaxis.label.set_color(gDTG.get_color())\n",
    "    \n",
    "    graphs=[gTGA,gDTG]\n",
    "    \n",
    "    TGA.set_title('{} - {}, {:.2f} mg'.format(get_label(TG_IR.info['sample']),TG_IR.info['run'],TG_IR.info['mass']))\n",
    "    plt.show()\n",
    "    \n",
    "    if save==True:\n",
    "        fig.savefig(os.path.join(dir_plots,'TGA','{}_{}_TG.png'.format(get_label(TG_IR.info['sample']),TG_IR.info['run'])), bbox_inches='tight', dpi=300)\n",
    "\n",
    "def plot_FTIR(TG_IR,save=False,gases=[],x_axis='Ts',y_axis='orig'):\n",
    "    colors =plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "    x=TG_IR.ir[x_axis]\n",
    "    if gases==[]:\n",
    "        gases=TG_IR.gases\n",
    "    if y_axis=='rel':\n",
    "        gases=TG_IR.linreg.index\n",
    "        \n",
    "    #setup figure and plot first gas\n",
    "    fig, g1=plt.subplots()\n",
    "    fig.subplots_adjust(right=.8)\n",
    "    #\n",
    "    if x_axis=='t':\n",
    "        x=x/60\n",
    "        g1.set_xlabel('t /min')\n",
    "    elif x_axis=='Ts':\n",
    "        g1.set_xlabel('T /째C')    \n",
    "    if y_axis=='orig':\n",
    "        g1.set_ylabel(get_label(gases[0])+' /AU')\n",
    "        g1.yaxis.label.set_color(colors[0])\n",
    "        g1.plot(x,TG_IR.ir[gases[0]])\n",
    "    elif y_axis=='rel':\n",
    "        g1.set_ylabel('mmol$g^{-1}s^{-1}$')\n",
    "        g1.plot(x,TG_IR.ir[gases[0]],label=get_label(gases[0]))\n",
    "\n",
    "    \n",
    "    #append secondary, third... y-axis on right side\n",
    "    graph=[] \n",
    "    props=[]\n",
    "    for i,gas in enumerate(gases[1:]):\n",
    "        if y_axis=='orig':\n",
    "            y=TG_IR.ir[gas]\n",
    "            \n",
    "            graph.append(g1.twinx())\n",
    "            graph[i].spines['right'].set_position(('axes',1+i*.1))\n",
    "            graph[i].plot(x,y, color=colors[i+1])\n",
    "            graph[i].set_ylabel(get_label(gas)+' /AU')\n",
    "            graph[i].yaxis.label.set_color(colors[i+1])\n",
    "            \n",
    "        elif y_axis=='rel':\n",
    "            tot_area=np.sum(TG_IR.ir[gas])\n",
    "            tot_mol=(tot_area-TG_IR.linreg['intercept'][gas])/TG_IR.linreg['slope'][gas]*1000/TG_IR.info['dry_mass']\n",
    "            y=TG_IR.ir[gas]/tot_area*tot_mol\n",
    "            g1.plot(x,y,label=get_label(gas))\n",
    "\n",
    "    plt.legend()\n",
    "    g1.set_title('{} - {}, {:.2f} mg'.format(get_label(TG_IR.info['sample']),TG_IR.info['run'],TG_IR.info['mass']))\n",
    "    plt.show()\n",
    "    \n",
    "    if save==True:\n",
    "        fig.savefig(os.path.join(dir_plots,'IR','{}_{}_IR.png'.format(get_label(TG_IR.info['sample']),TG_IR.info['run'])), bbox_inches='tight', dpi=300)\n",
    "        \n",
    "def FTIR_to_DTG(TG_IR,x_axis='Ts',save=False,gases=[]):\n",
    "    if gases==[]:\n",
    "        gases=TG_IR.linreg.index\n",
    "\n",
    "    Stoffdaten=pd.DataFrame({'co2':44.01,'co':28.01,'h2o':18.02,'caox':128.10},index=['M'])\n",
    "    data=pd.merge(TG_IR.tga,TG_IR.ir,how='left',on=['t','Ts']).dropna()\n",
    "    DTG=-sp.signal.savgol_filter(data['mass'], 13, 3, deriv=1)\n",
    "    \n",
    "    x=data[x_axis]\n",
    "    y=np.zeros((len(gases),len(TG_IR.ir)))\n",
    "    out=pd.DataFrame()\n",
    "    out['t']=data['t']\n",
    "    out['Ts']=data['Ts']\n",
    "    cumul=np.zeros(len(TG_IR.ir))\n",
    "    for i,gas in enumerate(gases):\n",
    "        tot_area=np.sum(TG_IR.ir[gas])\n",
    "        tot_mass=(tot_area-TG_IR.linreg['intercept'][gas])/TG_IR.linreg['slope'][gas]*Stoffdaten[gas]['M']\n",
    "        y[i][:]=TG_IR.ir[gas]/tot_area*tot_mass\n",
    "        out[gas]=y[i][:]\n",
    "        cumul+=y[i][:]\n",
    "   \n",
    "    #setup\n",
    "    fig=plt.figure(constrained_layout=True)\n",
    "    gs = fig.add_gridspec(8, 1)\n",
    "    stack= fig.add_subplot(gs[:-1, 0])\n",
    "    stack.set_title('{} - {}, {:.2f} mg'.format(get_label(TG_IR.info['sample']),TG_IR.info['run'],TG_IR.info['mass']))\n",
    "    error = fig.add_subplot(gs[-1,0],sharex=stack)\n",
    "\n",
    "    #plotting of fit\n",
    "\n",
    "    if x_axis=='Ts':\n",
    "        stack.set_xlabel('T /째C')\n",
    "        error.set_xlabel('T /째C')\n",
    "    elif x_axis=='t':\n",
    "        x=x/60\n",
    "        stack.set_xlabel('t /min')\n",
    "        error.set_xlabel('t /min')\n",
    "        temp=stack.twinx()\n",
    "        temp.plot(x,data['Ts'],ls='dashed',color='black',label='T')\n",
    "        temp.set_ylabel('T /째C')\n",
    "        temp.legend(loc=1)\n",
    "        \n",
    "    stack.stackplot(x,y,labels=[get_label(gas) for gas in gases])\n",
    "    stack.plot(x,DTG,label='DTG')\n",
    "    stack.set_ylabel('DTG, {} /$mg s^{{-1}}$'.format((', '.join([get_label(gas) for gas in gases]))))\n",
    "    stack.legend(loc=2)\n",
    "    error.plot(x,DTG-cumul)\n",
    "    error.hlines(0,min(x),max(x),ls='dashed')\n",
    "    \n",
    "    error.set_ylabel('$\\Delta$ DTG')\n",
    "    fig.show()\n",
    "    if save==True:\n",
    "        fig.savefig(os.path.join(dir_plots,'IRDTG','{}_IRDTG.png'.format(TG_IR.info['name'])), bbox_inches='tight', dpi=300)\n",
    "        out['dtg']=DTG\n",
    "        out.to_excel(os.path.join(dir_output,TG_IR.info['name']+'_IRDTG.xlsx'))\n",
    "    \n",
    "def plot_gauss(x,*args):\n",
    "    n=int(len(args)/3)\n",
    "    A=args[:n]\n",
    "    mu=args[n:2*n]\n",
    "    sig=args[2*n:len(args)]\n",
    "    for i in range(len(A)):\n",
    "        y=gaussian(x,A[i],mu[i],sig[i])\n",
    "        plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```corr_TGA``` takes TGA-data and corrects it by the buoyancy blank value.\n",
    "\n",
    "```corr_FTIR``` takes FTIR-data and corrects the $CO_{2}$-signal. The signal has a consistant fluctuation, even when there is no analyte present due to the pressure fluctuations produced by the adsorption dryer, that is used to flush the FTIR constanly. A baseline measurement without analyte is shifted in both dimensions, so that it is in phase with the fluctuation in the data and then substracted from it and the minimum is set to zero by substracting the former minimum.\n",
    "\n",
    "```baseline_als``` was taken from https://stackoverflow.com/questions/29156532/python-baseline-correction-library and based on the paper *Baseline Correction with Asymmetric Least Squares Smoothing* by Paul H. C. Eilers Hans F.M. Boelens\n",
    "October 21, 2005.\n",
    "\n",
    "```const_baseline``` calculates a constant baseline value that, when subtracted, minimizes the influence of noise on the quantification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def corr_TGA(TGA,file_baseline,plot=False):\n",
    "    path_baseline=find_files(file_baseline,'.txt',dir_data)[0]\n",
    "    #opens the buoyancy blank value 'baseline' and substracts them from the original data \n",
    "    try:\n",
    "        blindwert=pd.read_csv(path_baseline, delim_whitespace=True,decimal=',' ,names=['Index','t','Ts','Tr','mass'],skiprows=13, skipfooter=11,converters={'mass': lambda x: float(x.replace(',','.'))}).drop(columns='Index')\n",
    "    except:\n",
    "        print('>',path_baseline,' konnte nicht gefunden werden.')\n",
    "        return None\n",
    "    \n",
    "    corr_data=TGA.copy()\n",
    "    corr_data['mass']=corr_data['mass'].subtract(blindwert['mass'][:len(TGA)])\n",
    "    \n",
    "    #plotting of data, baseline and corrected value\n",
    "    if plot==True:\n",
    "        fig=plt.figure()\n",
    "        \n",
    "        x=TGA['Ts']\n",
    "        y=TGA['mass']\n",
    "        plt.plot(x,y,label='data')\n",
    "        plt.plot(x,blindwert['mass'][:len(TGA)],label='baseline')\n",
    "        plt.plot(x,corr_data['mass'],label='corrected')\n",
    "        plt.xlabel('T /째C')\n",
    "        plt.ylabel(y.name+' /mg')\n",
    "        plt.legend()\n",
    "        plt.title('TGA baseline correction')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    return corr_data\n",
    "\n",
    "def corr_FTIR(FTIR,file_baseline,save=False,plot=False):\n",
    "    #opens FTIR data of the baseline and takes the 'co2' column\n",
    "    corr_data=FTIR.copy()\n",
    "    try:\n",
    "        baseline=read_FTIR(file_baseline)\n",
    "        baseline=np.array(baseline['co2'])\n",
    "\n",
    "        #in the baseline the peaks and valleys as well as the amplitude of the baseline are determined\n",
    "        peaks_baseline,properties_baseline=find_peaks(baseline,height=[None,None])#,height=[tol*min(baseline),tol*max(baseline)])\n",
    "        valleys_baseline,valley_properties_baseline=find_peaks(-baseline,height=[None,None])#,height=[tol*min(-baseline),tol*max(-baseline)])\n",
    "        amplitude_baseline=np.mean(properties_baseline['peak_heights'])+np.mean(valley_properties_baseline['peak_heights'])\n",
    "\n",
    "        #in the original data the peaks and valleys that have similar height as the baseline are determined\n",
    "        tol=1.5\n",
    "        peaks,properties=find_peaks(FTIR['co2'],height=[-tol*amplitude_baseline,tol*amplitude_baseline])\n",
    "        valleys,valley_properties=find_peaks(-FTIR['co2'],height=[None,None],prominence=amplitude_baseline*.05) \n",
    "\n",
    "        #the median distance between between baseline-peaks, the period is determined\n",
    "        dist_peaks=np.diff(peaks_baseline)\n",
    "        len_period=int(np.median(dist_peaks))\n",
    "\n",
    "        #determination of the phase shift in x direction by checking if there is also a valley in the baseline in proximity\n",
    "        #the x shift is calculated as the median of the differences\n",
    "        dists=[]\n",
    "        j=0\n",
    "        for valley in valleys:\n",
    "            while j<len(valleys_baseline)-1 and (valleys_baseline[j]-valley <=0):\n",
    "                j=j+1\n",
    "            if valleys_baseline[j]-valley>=0:\n",
    "                dists.append(valleys_baseline[j]-valley)\n",
    "\n",
    "        x_shift=int(sp.stats.mode(dists)[0])\n",
    "\n",
    "        ###modifying of the baseline  \n",
    "        #elongating the baseline by one period\n",
    "        periode=baseline[:len_period]\n",
    "        co2_baseline=np.concatenate((periode,baseline), axis=None)\n",
    "\n",
    "        #shifting the baseline in x direction\n",
    "        c=[]\n",
    "        for x_offs in range(-1,len_period%x_shift+1):\n",
    "            peaks,props=find_peaks(FTIR['co2']-co2_baseline[x_shift+x_offs:len(FTIR)+x_shift+x_offs],height=[None,None],prominence=amplitude_baseline*.02)\n",
    "            c.append(len(peaks))\n",
    "        x_offs=np.where(c==np.min(c))[0][0]-1\n",
    "\n",
    "        co2_baseline=co2_baseline[x_shift+x_offs:len(FTIR)+x_shift+x_offs]\n",
    "        \n",
    "    except:\n",
    "        print('No CO2 baseline found.')\n",
    "        co2_baseline=np.zeros(len(FTIR))\n",
    "\n",
    "    h2o_baseline=np.zeros(len(FTIR))\n",
    "    \n",
    "    ##return value\n",
    "    \n",
    "    corr_data['co']=corr_data['co'].subtract(min(corr_data['co']))\n",
    "    corr_data['co']=corr_data['co'].subtract(const_baseline(corr_data['co'],0.002))\n",
    "    corr_data['co2']=corr_data['co2'].subtract(co2_baseline)\n",
    "    corr_data['co2']=corr_data['co2'].subtract(min(corr_data['co2']))\n",
    "    corr_data['co2']=corr_data['co2'].subtract(const_baseline(corr_data['co2'],0.07))\n",
    "    corr_data['h2o']=corr_data['h2o'].subtract(h2o_baseline)\n",
    "    corr_data['h2o']=corr_data['h2o'].subtract(min(corr_data['h2o']))\n",
    "    corr_data['h2o']=corr_data['h2o'].subtract(const_baseline(corr_data['h2o'],0.001))\n",
    "    \n",
    "    \n",
    "    ###plotting of baseline, data and the corrected data\n",
    "    if plot==True:\n",
    "        \n",
    "        fig=plt.figure()\n",
    "        try:\n",
    "            x=FTIR['Ts']\n",
    "        except:\n",
    "            x=FTIR['t']\n",
    "        y=co2_baseline\n",
    "\n",
    "        \n",
    "        plt.plot(x,FTIR['co2'],label='data')\n",
    "        plt.plot(x,baseline[:len(x)], label='baseline')\n",
    "        plt.plot(x,y,label='corr. baseline')#,alpha=.5)\n",
    "        plt.plot(x,corr_data['co2'],label='corr. data')\n",
    "        plt.hlines(0,min(x),max(x),ls='dashed')\n",
    "        \n",
    "        plt.vlines(x.iloc[valleys],min(co2_baseline),max(FTIR['co2']-y),linestyle='dashed')\n",
    "        plt.legend()\n",
    "        if x.name=='t':    \n",
    "            plt.xlabel(x.name+' /min')\n",
    "        elif x.name=='Ts':    \n",
    "            plt.xlabel('T /째C')\n",
    "        plt.ylabel('$CO_2$ /AU')\n",
    "        plt.title('$CO_2$ baseline correction')\n",
    "        fig.savefig(os.path.join(dir_plots,'IR','IR_corr.png'), bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        fig=plt.figure()\n",
    "        \n",
    "        y=h2o_baseline\n",
    "        plt.plot(x,FTIR['h2o'],label='data')\n",
    "        plt.plot(x,y,label='baseline')\n",
    "        plt.plot(x,corr_data['h2o'],label='corr. data')\n",
    "        plt.hlines(0,min(x),max(x),ls='dashed')\n",
    "        \n",
    "        plt.legend()\n",
    "        if x.name=='t':    \n",
    "            plt.xlabel(x.name+' /min')\n",
    "        elif x.name=='Ts':    \n",
    "            plt.xlabel('T /째C')\n",
    "        plt.ylabel('AU')\n",
    "        plt.title('$H_2O$ baseline correction')\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    if save==True:\n",
    "        out=pd.DataFrame()\n",
    "        out['t']=x\n",
    "        out['data']=FTIR['co2']\n",
    "        out['baseline']=baseline[:len(x)]\n",
    "        out['corr_baseline']=co2_baseline\n",
    "        out['corr_data']=corr_data['co2']\n",
    "        out.to_excel('baseline.xlsx')\n",
    "    return corr_data\n",
    "\n",
    "def baseline_als(y, lam=1e6, p=0.01, niter=10): #https://stackoverflow.com/questions/29156532/python-baseline-correction-library\n",
    "    L = len(y)\n",
    "    D = sp.sparse.csc_matrix(np.diff(np.eye(L), 2))\n",
    "    w = np.ones(L)\n",
    "    for i in range(niter):\n",
    "        W = sp.sparse.spdiags(w, 0, L, L)\n",
    "        Z = W + lam * D.dot(D.transpose())\n",
    "        z = sp.sparse.linalg.spsolve(Z, w*y)\n",
    "        w = p * (y > z) + (1-p) * (y < z)\n",
    "    return z\n",
    "\n",
    "def const_baseline(data,thres):\n",
    "    baseline=data[data<thres]\n",
    "    \n",
    "    if len(baseline)==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.sum(baseline)/len(baseline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```dry_weight``` takes the TGA data and returns the dry-weight of the sample as well as the dry mass loss. The moment where the sample is dry is derived from the *d짼TG*-signal, where the first peak is assumed to be from the the desorption of physisorbed water.\n",
    "\n",
    "```read_TGA``` opens the TGA-file in the given path and returns its content as a table.\n",
    "\n",
    "```read_FTIR``` opens the FTIR-files in the given path and returns a table containing the absorbance at each given time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "####dry_weight sollte masse des wassers aus IR abziehen? gas adsorption ist dann im gewicht enthalten\n",
    "\n",
    "def dry_weight(TG_IR,plot=False):\n",
    "    #calculating and smoothing of DTG\n",
    "    window_length=51\n",
    "    polyorder=3\n",
    "    \n",
    "    h2o=TG_IR.ir['h2o']\n",
    "    DTG=-sp.signal.savgol_filter(h2o, window_length, polyorder, deriv=1)\n",
    "    d2TG=-sp.signal.savgol_filter(h2o, window_length, polyorder, deriv=2)\n",
    "    \n",
    "    peaks,properties=find_peaks(DTG,height=.0001,width=0,rel_height=1)#.5e-7\n",
    "    end=properties['right_ips'].astype(np.int, copy=False)\n",
    "    min_T=80\n",
    "    max_T=250\n",
    "    min_i=TG_IR.ir['Ts'][TG_IR.ir['Ts']>min_T].index[0]\n",
    "    max_i=TG_IR.ir['Ts'][TG_IR.ir['Ts']>max_T].index[0]    \n",
    "\n",
    "    dry_point=TG_IR.ir['t'][peaks[0]:][DTG[peaks[0]:]<0.000075].iloc[0]#TG_IR.ir['t'].iloc[step_end[0]]#max(step_end)\n",
    "    \n",
    "    #getting the dry_mass at the dry_point as well as the final weight and calculating the relative\n",
    "    #mass-loss and the water content from it\n",
    "    dry_mass=TG_IR.tga['mass'][dry_point]\n",
    "    fin_weight=TG_IR.tga['mass'][len(TG_IR.tga)-1]\n",
    "    mass_loss=(dry_mass-fin_weight)\n",
    "    rel_mass_loss=mass_loss/dry_mass\n",
    "    dry_time=TG_IR.tga['t'][dry_point]\n",
    "    dry_temp=TG_IR.tga['Ts'][dry_point]\n",
    "    water_content=(TG_IR.info['mass']-dry_mass)/dry_mass\n",
    "    \n",
    "    #write information in dictionary\n",
    "    dry_info={}\n",
    "    dry_info['dry_mass']=dry_mass\n",
    "    dry_info['fin_mass']=fin_weight\n",
    "    dry_info['ml_n2']=mass_loss\n",
    "    dry_info['rel_ml_n2']=rel_mass_loss\n",
    "    dry_info['dry_temp']=dry_temp\n",
    "    dry_info['dry_time']=dry_time\n",
    "    dry_info['water_content']=water_content\n",
    "    \n",
    "    #plotting\n",
    "    if plot==True:\n",
    "        fig=plt.figure()\n",
    "        x=TG_IR.tga['Ts']\n",
    "        y=TG_IR.tga['mass']\n",
    "        plt.plot(x,y,label='TGA')\n",
    "        #Trockenpunkt zeichnen\n",
    "        plt.annotate(s='', xy=(x[dry_point],min(y)), xytext=(x[dry_point],y[dry_point]), arrowprops=dict(arrowstyle='<->'))\n",
    "        plt.scatter(x[dry_point],y[dry_point],c='r')\n",
    "        plt.hlines(fin_weight,x[dry_point],max(x),linestyle='dashed')\n",
    "        plt.text(x[dry_point]+20,y[dry_point],'dry weight: '+str(round(y[dry_point],2))+' mg @ '+str(round(x[dry_point],2))+' 째C')\n",
    "        plt.text(x[dry_point]+20,(y[dry_point]+ fin_weight)/2,'mass loss: '+str(round(mass_loss,2))+' mg ('+str(round(rel_mass_loss*100,2))+' %)')\n",
    "        plt.ylabel('TGA /mg')\n",
    "        plt.xlabel('T /째C')\n",
    "        ax2=plt.twinx()\n",
    "        ax2.plot(TG_IR.ir['Ts'],h2o,label='h2o',linestyle='dashed')\n",
    "        ax2.set_ylabel('DTG')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    return dry_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def read_TGA(file,profile='Otto'):\n",
    "    #open file from TGA in given directory and make a DataFrame from it\n",
    "    path=find_files(file,'.txt',dir_data)[0]\n",
    "    \n",
    "    if profile=='Otto':\n",
    "        skiprows=13\n",
    "        skipheader=7\n",
    "        \n",
    "    if profile=='Falk':\n",
    "        skiprows=11\n",
    "        skipheader=6\n",
    "        \n",
    "    try:\n",
    "        data=pd.read_csv(path, delim_whitespace=True,decimal=',' ,names=['Index','t','Ts','Tr','mass'],skiprows=skiprows, skipfooter=11,converters={'mass':lambda x: float(x)}).drop(columns='Index')\n",
    "        \n",
    "    except:\n",
    "        return\n",
    "    \n",
    "    #check if there is heat flow information and append it \n",
    "    try:\n",
    "        path_mW=find_files(file,'_mW.txt',dir_data)[0]\n",
    "        data['heat_flow']=pd.read_csv(path_mW, delim_whitespace=True,decimal=',' ,names=['Index','t','Ts','Tr','heat_flow'],skiprows=skiprows, skipfooter=11, usecols=['heat_flow'])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    #extract information on the measurement from the header and footer of the TGA file\n",
    "    footer=pd.read_table(path,encoding='ansi',skipfooter=2,index_col=False,names=[0]).tail(3)\n",
    "    header=pd.read_table(path,encoding='ansi',skiprows=skipheader,nrows=1,index_col=False,names=[0])\n",
    "    \n",
    "    header=str(header.iloc[0,0])\n",
    "    name=re.search('\\S+(?=,)',header).group()\n",
    "    date=header[header.find(',')+2:header.rfind(' ')].strip()\n",
    "    time=header[header.rfind(' ')+1:].strip()\n",
    "    method_name=str(footer.iloc[2,0]).strip()\n",
    "    mass=str(footer.iloc[0,0]).strip()\n",
    "    mass=pd.to_numeric(mass[mass.find(',')+1:-3].replace(',','.'))\n",
    "    \n",
    "    #if the sample wasn't weighed in automatically, the mass at t=0 is used instead\n",
    "    if mass==0:\n",
    "        mass=data['mass'][0]\n",
    "    \n",
    "\n",
    "    # extract method info from method\n",
    "    last_i=0\n",
    "    values=[]\n",
    "    parameters=[]\n",
    "    for i in range(len(method_name)):\n",
    "        if method_name[i]=='=':\n",
    "            parameters.append('background_state')\n",
    "            \n",
    "        elif method_name[i]=='<':\n",
    "            parameters.append('lower_temp')\n",
    "            \n",
    "        elif (method_name[i]=='>') or (method_name[i]=='/'):\n",
    "            parameters.append('high_temp')\n",
    "        \n",
    "        elif (method_name[i]==')') and (method_name[last_i-1]=='('):\n",
    "            parameters.append('method_gas')\n",
    "            \n",
    "        elif (method_name[i]=='(') and (method_name[last_i-1]=='/'):\n",
    "            parameters.append('gradient')\n",
    "            \n",
    "        elif (method_name[i]=='/') and (method_name[last_i-1]=='<'):\n",
    "            parameters.append('high_temp')\n",
    "            \n",
    "        if (method_name[i] in '=<>()/')==True:\n",
    "            val=method_name[last_i:i]\n",
    "            if val.isnumeric() ==True:\n",
    "                val=int(val)\n",
    "            values.append(val)\n",
    "            last_i=i+1\n",
    "    \n",
    "    parameters.append('crucible')\n",
    "    values.append(method_name[method_name.rfind('_')+1:])\n",
    "    \n",
    "    #write information in dictionary\n",
    "    info={}\n",
    "    info['name']=name\n",
    "    #info['sample']=name[name.rfind('6.6_')+4:name.rfind('6.6_')+9]\n",
    "    #info['sample']=re.search('\\d{5}',name).group()\n",
    "    try:\n",
    "        sample=re.search('(?<=\\d_)\\w[^_]+(?=_\\d{2,3})',name).group()\n",
    "    except:\n",
    "        sample=name\n",
    "    try:\n",
    "        info['sample']=int(sample)\n",
    "    except:\n",
    "        info['sample']=sample\n",
    "    info['run']=re.search('(?<=_)\\d{2,3}(?=_|$)',name).group()\n",
    "    info['method_name']=method_name\n",
    "    info['date']=date\n",
    "    info['time']=time\n",
    "    info['mass']=mass\n",
    "    info['method_param']=parameters\n",
    "    info['method_value']=values\n",
    "    \n",
    "    return data,info\n",
    "\n",
    "def read_FTIR(file_name):\n",
    "    files=find_files(file_name,'.csv',dir_data)\n",
    "    #find the gases by looking at the suffix of the files\n",
    "    gases=[]\n",
    "    paths=[]\n",
    "    for file in files:\n",
    "        gases.append(file[file.rfind('_')+1:file.rfind('.')].lower())\n",
    "        paths.append(file)  \n",
    "    if gases==[]:\n",
    "        return\n",
    "    else:\n",
    "        #make DataFrame with the first gas, keeping the time column\n",
    "        data=pd.read_csv(files[0], delimiter=';', decimal=',', names=['t',gases[0]])\n",
    "    \n",
    "        #append the IR data from the other gases as new columns\n",
    "        for i in range(1,len(gases)):\n",
    "            data[gases[i]]=pd.read_csv(files[i], delimiter=';', decimal=',', names=['t',gases[i]], usecols=[gases[i]])\n",
    "        data['t']=((data['t']+5)*60).astype(int)\n",
    "        return data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```massestufe``` takes TGA-data and calculates the mass steps. For that the first order derivative of the TG-values is used, DTG. The signal is evaluated for peaks and the peak-boundaries on either side are determined with the *find_peaks*-function from the *SciPy*-library. The right boundaries of the DTG-peaks mark the start of a mass step  and the height of the mass step is calculated as the mean TGA-value over a given number of samples, starting from said boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def massestufe(TGA,rel_height=.98,plot=False): #rel_height=.963\n",
    "    #Berechnung und Gl채ttung von DTG\n",
    "    window_length=201\n",
    "    polyorder=3\n",
    "    \n",
    "    TG=(TGA['mass']/TGA['mass'][0])\n",
    "    if window_length == 0:\n",
    "        DTG=pd.Series(np.gradient(TG))\n",
    "    else:\n",
    "        DTG=sp.signal.savgol_filter(TG, window_length, polyorder, deriv=1)\n",
    "  \n",
    "    #Finden der Stufen\n",
    "    peaks,properties=find_peaks(-DTG,height=0.00025,width=0,rel_height=rel_height)\n",
    "    step_end=properties['right_ips'].astype(np.int, copy=False)\n",
    "    step_start=properties['left_ips'].astype(np.int, copy=False)\n",
    "    \n",
    "    #Berechnen der Massen der Stufen\n",
    "    stufen=np.zeros(len(peaks))\n",
    "    samples=20\n",
    "    for i in range(len(peaks)):\n",
    "        stufen[i]=np.mean(TGA['mass'][step_end[i]:step_end[i]+samples])\n",
    "    \n",
    "    #Berechnen der Stufenh철he\n",
    "    stufenh철he=np.zeros(len(stufen))\n",
    "    stufen=np.insert(stufen,0,TGA['mass'][0])\n",
    "        \n",
    "    stufenh철he=np.zeros(len(step_start))\n",
    "    for i in range(len(step_start)):\n",
    "        stufenh철he[i]=np.mean(TGA['mass'][step_start[i]-samples:step_start[i]])-np.mean(TGA['mass'][step_end[i]:step_end[i]+samples])\n",
    "    \n",
    "    #print(stufenh철he)\n",
    "    rel_stufenh철he=stufenh철he/stufen[0]*100\n",
    "    \n",
    "    #Plotten\n",
    "    if plot==True:\n",
    "        #Plotten von DTG\n",
    "        fig=plt.figure()\n",
    "        x=TGA['Ts']\n",
    "        y=-DTG\n",
    "        plt.plot(x,y)\n",
    "        plt.vlines(x[step_end],0,max(y),linestyle='dashed')\n",
    "        plt.vlines(x[step_start],0,max(y),linestyle='dashed')\n",
    "        plt.vlines(x[peaks],y[peaks]-properties['peak_heights'],y[peaks])\n",
    "        plt.hlines(y[peaks]-properties['peak_heights'],x[step_end],x[step_start])\n",
    "        plt.xlabel(x.name+' /째C')\n",
    "        plt.ylabel('DTG /mg/째C')\n",
    "        plt.title('DTG')\n",
    "        plt.show()\n",
    "        \n",
    "        #Plotten der gefundenen Stufen\n",
    "        fig=plt.figure()\n",
    "        plt.hlines(stufen[:-1],np.zeros(len(stufen)),x[step_end],linestyle='dashed')\n",
    "        plt.vlines(x[step_end],stufen[1:],stufen[:-1],linestyle='dashed')\n",
    "        for i in range(len(step_end)):\n",
    "            plt.text(x[step_end[i]]+5,stufen[i+1]+stufenh철he[i]/2,str(round(stufenh철he[i],3))+' mg ('+str(round(rel_stufenh철he[i],2))+' %)')\n",
    "        plt.plot(x,TGA['mass'])\n",
    "        plt.xlabel(x.name+' /째C')\n",
    "        plt.ylabel('mass /mg')\n",
    "        plt.title('TG')\n",
    "        plt.show()\n",
    "        \n",
    "        #Plotten der rel Stufen\n",
    "        fig=plt.figure()\n",
    "        rel_stufen=stufen/stufen[0]*100\n",
    "        plt.hlines(rel_stufen[:-1],np.zeros(len(rel_stufen)),x[step_end],linestyle='dashed')\n",
    "        plt.vlines(x[step_end],rel_stufen[1:],rel_stufen[:-1],linestyle='dashed')\n",
    "        for i in range(len(step_end)):\n",
    "            plt.text(x[step_end[i]]+5,rel_stufen[i+1]+rel_stufenh철he[i]/2,str(round(rel_stufenh철he[i],2))+' %')\n",
    "        plt.plot(x,TGA['mass']/TGA['mass'][0]*100)\n",
    "        plt.text(800,95,str(round(TGA['mass'][0],2))+' mg', horizontalalignment='center')\n",
    "        plt.xlabel('T /째C')\n",
    "        plt.ylabel('rel. mass /%')\n",
    "        plt.title('TG')\n",
    "        plt.show()\n",
    "        \n",
    "    return stufenh철he,rel_stufenh철he,step_start,step_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```integrate_peaks``` takes FTIR-data and the mass step boundaries determined in ```massestufe``` and used them to integrate the gas-signals between the given boundaries and returns them in form of a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_peaks(FTIR,step_start,step_end,corr_baseline=None,plot=False):\n",
    "    gases=['co','co2','h2o']\n",
    "    \n",
    "    #Umrechnen des Stufenstarts f체rs FTIR. Zeitversatz durch Wartezeit und Transferline\n",
    "    step_start=step_start+60\n",
    "    step_end=step_end+60\n",
    "   # print(step_start,step_end)\n",
    "    integrals=pd.DataFrame(columns=[0,1,2],index=gases)\n",
    "    \n",
    "    #Plotten mit Integrationsgrenzen\n",
    "    if plot==True:\n",
    "        x=FTIR['t']\n",
    "        y=FTIR[['co','co2','h2o']]\n",
    "    \n",
    "        fig, h2o=plt.subplots()\n",
    "        fig.subplots_adjust(right=.8)\n",
    "    \n",
    "        co=h2o.twinx()\n",
    "        co2=h2o.twinx()\n",
    "\n",
    "        co2.spines['right'].set_position(('axes',1.15))\n",
    "    \n",
    "        gco,=co.plot(x,FTIR['co'],'r-',label='CO')\n",
    "        gco2,=co2.plot(x,FTIR['co2'],'b-',label='CO2')\n",
    "        gh2o,=h2o.plot(x,FTIR['h2o'],'g-',label='H2O')\n",
    "        co2.vlines(step_end,0,max(FTIR['co2']),linestyle='dashed')\n",
    "        co2.vlines(step_start,0,max(FTIR['co2']),linestyle='dashed')\n",
    "    \n",
    "        h2o.set_xlabel('t /Min')\n",
    "        h2o.set_ylabel('H2O')\n",
    "        co.set_ylabel('CO')\n",
    "        co2.set_ylabel('CO2')\n",
    "        \n",
    "        h2o.yaxis.label.set_color(gh2o.get_color())\n",
    "        co.yaxis.label.set_color(gco.get_color())\n",
    "        co2.yaxis.label.set_color(gco2.get_color())\n",
    "    \n",
    "        graphs=[gco,gco2,gh2o]\n",
    "    \n",
    "        h2o.legend(graphs,[g.get_label() for g in graphs])\n",
    "        plt.title('Absorbance')\n",
    "    \n",
    "    #Integration\n",
    "    for gas in gases:\n",
    "        for i in range(len(step_end)):\n",
    "            subset=FTIR[gas][(FTIR['t']>=step_start[i]) & (FTIR['t']<=step_end[i])]\n",
    "            #Baseline correction\n",
    "            if corr_baseline=='linear':\n",
    "                baseline=np.linspace(subset.iloc[0],subset.iloc[len(subset)-1],len(subset))\n",
    "            elif corr_baseline=='const':\n",
    "                baseline=min(subset.iloc[0],subset.iloc[len(subset)-1])*np.ones(len(subset))#np.linspace(min(subset),min(subset),len(subset))\n",
    "            elif corr_baseline==None:\n",
    "                baseline=np.zeros(len(subset))\n",
    "                \n",
    "            integral=sp.integrate.simps(subset-baseline)   \n",
    "            integrals[i][gas]=integral\n",
    "            \n",
    "            if plot==True:\n",
    "                    x=FTIR['t'][(FTIR['t']>=step_start[i]) & (FTIR['t']<=step_end[i])]\n",
    "                    y=subset\n",
    "                    if gas=='co':\n",
    "                        co.plot(x,baseline,'r--')\n",
    "                    if gas=='co2':\n",
    "                        co2.plot(x,baseline,'b--')\n",
    "                    if gas=='h2o':\n",
    "                        h2o.plot(x,baseline,gh2o.get_color())\n",
    "    if plot==True:\n",
    "        plt.show()\n",
    "        print('Baseline correction: ',corr_baseline)\n",
    "        \n",
    "    return integrals \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```eval_lin``` returns the evaluation of a linear function $y=a\\cdot x +b$ with slope $a$ and intersect $b$ at a given point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lin(x,slope,intercept):\n",
    "    return slope*x+intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```calibration_stats``` calculates the detection limit $x_{NG}$ or $LOD$, limit of detection and limit of determination $x_{BG}$ or $LOQ$ based on *DIN 32645* in *mmol* as well as the residual and process standard deviation $s_{yx}$ and $s_{x0}$ in *FE* and *mmol*, respectively. Confidence is by default $\\alpha=.95=\\beta$, $k=3$ for the uncertainty of results $\\frac1k=.33$  and the number of analysis for the sample is $m=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_stats(x_Kali,y_Kali,linreg,alpha=.95,beta=None,m=1,k=3):\n",
    "    gases=linreg.index\n",
    "    \n",
    "    n=len(x_Kali)\n",
    "    if n==2:\n",
    "        return pd.DataFrame()\n",
    "    f=n-2\n",
    "    if beta==None:\n",
    "        beta=alpha\n",
    "    \n",
    "    stats=pd.DataFrame(columns=['s_yx','s_x0','x_NG','x_EG','x_BG'])\n",
    "    for gas in gases:\n",
    "        b=linreg['slope'][gas]\n",
    "        a=linreg['intercept'][gas]\n",
    "        \n",
    "        s_yx=np.sqrt(sum(np.power(b*x_Kali[gas]+a-y_Kali[gas],2))/(n-2))\n",
    "        s_x0=s_yx/b\n",
    "        x_=np.mean(x_Kali[gas])\n",
    "        Q_x=sum(np.power(x_Kali[gas]-x_,2))\n",
    "        \n",
    "        x_NG=s_x0*sp.stats.t.ppf(alpha,f)*np.sqrt(1/m+1/n+(x_*x_)/Q_x)\n",
    "        \n",
    "        x_EG=x_NG+s_x0*sp.stats.t.ppf(beta,f)*np.sqrt(1/m+1/n+(x_*x_)/Q_x)\n",
    "    \n",
    "        x_BG=k*x_NG\n",
    "                \n",
    "        stats=stats.append(pd.DataFrame([[s_yx,s_x0,x_NG,x_EG,x_BG]],index=[gas],columns=['s_yx','s_x0','x_NG','x_EG','x_BG']))\n",
    "    print('s_yx in FE\\ts_x0 in mmol\\tx_NG in mmol\\tx_EG in mmol\\tx_BG in mmol')\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```calibrate``` uses the samples and baseline measurements given in the file \"Kali.txt\" to calibrate the FTIR.\n",
    "The overall procedure contains of the following steps:\n",
    "1. correct the TGA and FTIR-data with the according functions\n",
    "2. calculate the mass steps\n",
    "3. calculate the integrals for each gas for each mass step\n",
    "4. calculate the theoretical amount of substance by dividing the according mass step by the molar mass\n",
    "5. appending the amount of substance and the integral to a dataset\n",
    "6. calculate the linear regression from the integral over the amount of substance for $CO_2$ and $H_{2}O$\n",
    "7. correct the amount of substance of $CO$ by the amount that is consumed in the water-gas shift reaction\n",
    "8. calculate the linear regression from the integral over the amount of substance for $CO$\n",
    "9. return the parameters of the regression in form of a table\n",
    "10. (optional) visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def calibrate(plot=False,sample_list=None):\n",
    "    Stoffdaten=pd.DataFrame({'co2':44.01,'co':28.01,'h2o':18.02,'caox':128.10},index=['M'])\n",
    "    gases=['h2o','co','co2'] \n",
    "    \n",
    "    #gespeicherte Kalibrierung laden\n",
    "    os.chdir(dir_cali)\n",
    "    try:\n",
    "        cali=pd.read_excel('cali.xlsx',sheet_name=None,index_col=0)\n",
    "        linreg=cali['linreg']\n",
    "        x_Kali=cali['x']\n",
    "        y_Kali=cali['y']\n",
    "        stats=cali['stats']\n",
    "        print('Hinterlegte Kalibrierung geladen.')\n",
    "        print(linreg)\n",
    "        \n",
    "    #neu kalibrieren\n",
    "    except:\n",
    "        print('Kalibriere...')\n",
    "        #Einlesen der Samplenamen und Baselines, die zur Kalibration genutzt werden sollen\n",
    "        samples=pd.read_csv(os.path.join(dir_samples,sample_list+'.txt'),delimiter='\\t')\n",
    "        \n",
    "        #initialisieren der DataFrames f체r x und y-werte\n",
    "        x_Kali=pd.DataFrame(columns=gases)\n",
    "        y_Kali=pd.DataFrame(columns=gases+['co_corr','co2_corr'])\n",
    "        \n",
    "        #Berechnen der Massenstufen und Integrale der FTIR-Signale f체r alle Proben\n",
    "        linreg=pd.DataFrame(columns=['slope','intercept','r_value','p_value','std_error'])\n",
    "        for i in range(len(samples)):\n",
    "            #Einlesen der Daten\n",
    "            path=samples['Samples'][i]\n",
    "            path_baseline=samples['Baseline'][i]\n",
    "\n",
    "            TGA,sample_info=read_TGA(path)\n",
    "            if sample_info['sample']!=18358:\n",
    "                print('Wrong sample for calibration.')\n",
    "                break\n",
    "            TGA=corr_TGA(TGA,path_baseline)\n",
    "            FTIR=read_FTIR(path)\n",
    "            FTIR=corr_FTIR(FTIR,path_baseline,plot=True)\n",
    "            \n",
    "            #update_samplelog(sample_info)\n",
    "            print('----------------------------------------------------')\n",
    "            print(sample_info)\n",
    "\n",
    "            #Berechnen der Massestufen und integration der Freistzungsraten\n",
    "            [steps,rel_steps,stepstart,stepend]=massestufe(TGA,plot=False)\n",
    "            integrals=integrate_peaks(FTIR,stepstart,stepend,plot=False,corr_baseline=None)\n",
    "\n",
    "            #Einf체gen der x-Werte (/mg) und y-Werte(/FE)\n",
    "            x_Kali=x_Kali.append({'co2':steps[2],'co':steps[1],'h2o':steps[0]},ignore_index=True)\n",
    "            y_Kali=y_Kali.append({'co2':integrals[2]['co2'],'co':integrals[1]['co'],'h2o':integrals[0]['h2o'],'co_corr':integrals[1]['co2'],'co2_corr':integrals[2]['co']},ignore_index=True)\n",
    "\n",
    "        #Lineare Regression\n",
    "        for gas in gases:\n",
    "            slope, intercept, r_value, p_value, std_err=sp.stats.linregress(x_Kali[gas],y_Kali[gas])\n",
    "            linreg=linreg.append(pd.DataFrame([[slope,intercept,r_value,p_value,std_err]],index=[gas],columns=['slope','intercept','r_value','p_value','std_error']))\n",
    "            plt.scatter(x_Kali[gas],y_Kali[gas])\n",
    "            plt.plot(x_Kali[gas],slope*x_Kali[gas]+intercept)\n",
    "            plt.text(0,0,str(slope))\n",
    "            plt.show()\n",
    "\n",
    "        #Korrektur        \n",
    "        colors =plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "        fig=plt.figure()\n",
    "        fig.set_size_inches(15,20)\n",
    "        n_iter=10\n",
    "        for i in range(n_iter):\n",
    "            #print('---------------------------\\n >> Iteration: ',i)\n",
    "            #Korrektur der CO2 masse um co masse im selben zersetzungsschritt\n",
    "            corr=(y_Kali['co2_corr']-linreg['intercept']['co'])/linreg['slope']['co']\n",
    "            temp=np.subtract(x_Kali['co2'],corr*(corr >0))#stats['x_BG']['co']))\n",
    "            \n",
    "            #neue regression\n",
    "            slope, intercept, r_value, p_value, std_err=sp.stats.linregress(temp,y_Kali['co2'])\n",
    "            \n",
    "            #zwischenspeichern\n",
    "            co2=pd.DataFrame([[slope,intercept,r_value,p_value,std_err]],index=['co2'],columns=['slope','intercept','r_value','p_value','std_error'])\n",
    "            \n",
    "            plt.subplot(211)\n",
    "            plt.title('co2')\n",
    "            plt.scatter(temp,y_Kali['co2'],color=colors[i],label='it. '+str(i+1))\n",
    "            plt.plot(temp,temp*slope+intercept,color=colors[i])\n",
    "            \n",
    "            #Korrektur der CO masse um co2 masse im selben zersetzungsschritt            \n",
    "            corr=(y_Kali['co_corr']-linreg['intercept']['co2'])/linreg['slope']['co2']\n",
    "            temp=np.subtract(x_Kali['co'],corr*(corr>0))#stats['x_BG']['co2']))\n",
    "            \n",
    "            #neue regression\n",
    "            slope, intercept, r_value, p_value, std_err=sp.stats.linregress(temp,y_Kali['co'])\n",
    " \n",
    "            #zwischenspeichern\n",
    "            co=pd.DataFrame([[slope,intercept,r_value,p_value,std_err]],index=['co'],columns=['slope','intercept','r_value','p_value','std_error'])\n",
    "                        \n",
    "            plt.subplot(212)\n",
    "            plt.title('co')\n",
    "            plt.scatter(temp,y_Kali['co'],color=colors[i],label='it. '+str(i+1))\n",
    "            plt.plot(temp,temp*slope+intercept,color=colors[i])\n",
    "            \n",
    "            linreg.update(co2)\n",
    "            linreg.update(co)\n",
    "            \n",
    "            stats=calibration_stats(x_temp,y_Kali,linreg)\n",
    "            \n",
    "        x_Kali['co']=x_Kali['co']-(y_Kali['co_corr']-linreg['intercept']['co2'])/linreg['slope']['co2']\n",
    "        x_Kali['co2']=x_Kali['co2']-(y_Kali['co2_corr']-linreg['intercept']['co'])/linreg['slope']['co']\n",
    "        \n",
    "        for gas in gases:\n",
    "            x_Kali[gas].update(x_Kali[gas]/Stoffdaten[gas]['M'])\n",
    "            \n",
    "            slope, intercept, r_value, p_value, std_err=sp.stats.linregress(x_Kali[gas],y_Kali[gas])\n",
    "        \n",
    "            temp=pd.DataFrame([[slope,intercept,r_value,p_value,std_err]],index=[gas],columns=['slope','intercept','r_value','p_value','std_error'])\n",
    "            linreg.update(temp)\n",
    "            \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        stats=calibration_stats(x_Kali,y_Kali,linreg)\n",
    "        \n",
    "        #speichern der Kalibrierung\n",
    "        with pd.ExcelWriter('cali.xlsx') as writer:\n",
    "            linreg.to_excel(writer,sheet_name='linreg')\n",
    "            x_Kali.to_excel(writer,sheet_name='x')\n",
    "            y_Kali.drop(['co_corr','co2_corr'],axis=1).to_excel(writer,sheet_name='y')\n",
    "            stats.to_excel(writer,sheet_name='stats')\n",
    "    \n",
    "    #Plotten der Regressionsgeraden und der zugrunde liegenden Daten\n",
    "    if plot:\n",
    "        for gas in gases:\n",
    "            fig=plt.figure()\n",
    "            x=x_Kali[gas]\n",
    "            y=y_Kali[gas]\n",
    "            \n",
    "            plt.scatter(x,y,label='data (N = {})'.format(len(x)))\n",
    "            \n",
    "            x=np.array((min(x),max(x)))\n",
    "            plt.plot(x,x*linreg['slope'][gas]+linreg['intercept'][gas],label='regression',ls='dashed')\n",
    "            plt.text(max(x),min(y),'y = {:.3f} $\\cdot$ x {:+.3f}, $R^2$ = {:.5}'.format(linreg['slope'][gas],linreg['intercept'][gas],str(linreg['r_value'][gas])),horizontalalignment='right')\n",
    "            plt.xlabel('mmol')\n",
    "            plt.ylabel('AU')\n",
    "            plt.title(get_label(gas))\n",
    "            plt.xlim(0,max(x)+abs(min(x)))\n",
    "            plt.legend(loc=0)\n",
    "            plt.show()\n",
    "            \n",
    "        fig=plt.figure()\n",
    "        for gas in gases:\n",
    "            x=x_Kali[gas]\n",
    "            y=y_Kali[gas]\n",
    "            \n",
    "            plt.scatter(x,y,label='data {} (N = {})'.format(get_label(gas),len(x)))\n",
    "            \n",
    "            x=np.array((min(x),max(x)))\n",
    "            plt.plot(x,x*linreg['slope'][gas]+linreg['intercept'][gas],label='regression {}'.format(get_label(gas)),ls='dashed')\n",
    "            plt.xlabel('mmol')\n",
    "            plt.ylabel('AU')\n",
    "            plt.xlim(0,max(x)+abs(min(x)))\n",
    "            plt.legend(loc=0)\n",
    "        plt.show()\n",
    "    os.chdir(home)\n",
    "    return linreg,stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```gaussian``` takes the parameters of the gaussian function and returns its value at a given point x:\n",
    "\n",
    "$g(x)=height\\cdot \\exp(-\\ln(2)\\cdot (\\frac{x-center}{hwhm})^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x,height,center,hwhm):\n",
    "    return height*np.exp(-np.log(2)*np.power((x-center)/hwhm,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```multi_gauss``` takes lists of parameters of the normal distribution and returns the sum of those distrubionts at a given point x:\n",
    "$\\sum_{i}^{n}g_{i}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def multi_gauss(x,*args):\n",
    "    n=int(len(args)/3)\n",
    "    heights=args[:n]\n",
    "    centers=args[n:2*n]\n",
    "    hwhms=args[2*n:len(args)]\n",
    "    \n",
    "    s=0\n",
    "    for i in range(n):\n",
    "        s=s+gaussian(x,heights[i],centers[i],hwhms[i])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```fitting``` takes FTIR-data, the gas to fit and a function to fit the data and returns the optimal parameters for the given function with the least sum of squares. The fit-function from the *SciPy*-library uses the *Levenberg-Marquardt* algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting(TG_IR,centers,labels,func,tol_center=30,max_hwhm=95,y_axis='orig',plot=False,save=True,init_offs=[0,0,0]):\n",
    "    gases=list(centers.columns.values)\n",
    "    if ('co2' in gases) and ('co' in gases):\n",
    "        gases.remove('co2')\n",
    "        gases.insert(0,'co2')\n",
    "    #thresholds for fit parameters\n",
    "    \n",
    "    #initializing output DataFrame\n",
    "    peaks=pd.DataFrame(columns=['center','height','hwhm','area','mmol','mmol_per_g'],index=[group+'_'+gas.upper() for gas in gases for group in labels[gas].dropna()]+[gas.upper() for gas in gases])\n",
    "    sumsqerr=pd.DataFrame(index=[TG_IR.info['name']],columns=gases)\n",
    "\n",
    "    #cycling through gases\n",
    "    FTIR=TG_IR.ir.copy()\n",
    "    for gas in gases:\n",
    "        #print(gas)\n",
    "        params=pd.DataFrame(columns=['min_center','init_center','max_center','min_height','init_height','max_height','min_hwhm','init_hwhm','max_hwhm'],index=[group+'_'+gas.upper() for group in labels[gas].dropna()])\n",
    "\n",
    "        if gas=='h2o':\n",
    "            FTIR[gas]-=baseline_als(FTIR[gas])\n",
    "            \n",
    "        #molar desorption\n",
    "        tot_area=np.sum(TG_IR.ir[gas])\n",
    "        if gas == 'h2o':\n",
    "            tot_area=np.sum(TG_IR.ir[gas][TG_IR.ir['Ts']>150])\n",
    "        tot_mol=(tot_area-TG_IR.linreg['intercept'][gas])/TG_IR.linreg['slope'][gas]\n",
    "        peaks['area'][gas.upper()]=tot_area\n",
    "        peaks['mmol'][gas.upper()]=tot_mol\n",
    "        peaks['mmol_per_g'][gas.upper()]=tot_mol/TG_IR.info['dry_mass']*1000\n",
    "        \n",
    "\n",
    "        \n",
    "        if y_axis=='rel':\n",
    "            FTIR.update(FTIR[gas]/tot_area*tot_mol)\n",
    "        \n",
    "        #initial guesses\n",
    "        init_centers=np.array(centers[gas].dropna().astype(float))+init_offs[0]\n",
    "        num_curves=len(init_centers)\n",
    "        max_heigth=max(FTIR[gas])\n",
    "        init_heights=(0.5+init_offs[1])*max_heigth*np.ones(num_curves)#.5*TG_IR.info['dry_mass']/200*np.ones(num_curves)#\n",
    "        init_hwhms=(0.5+init_offs[2])*max_hwhm*np.ones(num_curves)#0.5*max_hwhm\n",
    "        \n",
    "        #lower bounds for fit\n",
    "        min_heights=0*np.ones(num_curves)\n",
    "        min_hwhms=0*np.ones(num_curves)\n",
    "        min_centers=init_centers-tol_center\n",
    "        \n",
    "        #upper bounds for fit\n",
    "        max_heights=max_heigth*np.ones(num_curves)#init_heights+5*TG_IR.info['dry_mass']/200##\n",
    "        max_hwhms=max_hwhm*np.ones(num_curves)\n",
    "        max_centers=init_centers+tol_center\n",
    "        \n",
    "        #print(min_centers,init_centers,max_centers)\n",
    "        params['init_center']=init_centers\n",
    "        params['init_height']=init_heights\n",
    "        params['init_hwhm']=init_hwhms\n",
    "        params['min_center']=min_centers\n",
    "        params['min_height']=min_heights\n",
    "        params['min_hwhm']=min_hwhms\n",
    "        params['max_center']=max_centers\n",
    "        params['max_height']=max_heights\n",
    "        params['max_hwhm']=max_hwhms\n",
    "        #assumptions by figueiredo\n",
    "        a=True\n",
    "        if (gas=='co' and a==True):\n",
    "            try:\n",
    "                loc=labels[gas][labels[gas]=='anhydrides'].index[0]\n",
    "\n",
    "                init_heights[loc]=peaks['height']['anhydrides_CO2']/TG_IR.linreg['slope']['co2']*TG_IR.linreg['slope']['co']\n",
    "                min_heights[loc]=init_heights[loc]*.9\n",
    "                max_heights[loc]=init_heights[loc]*1.1\n",
    "\n",
    "                init_hwhms[loc]=peaks['hwhm']['anhydrides_CO2']\n",
    "                min_hwhms[loc]=init_hwhms[loc]*.9\n",
    "                max_hwhms[loc]=init_hwhms[loc]*1.1\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "        #guesses and bounds\n",
    "        init_guess=np.concatenate((init_heights,init_centers,init_hwhms))\n",
    "        min_param=np.concatenate((min_heights,min_centers,min_hwhms))\n",
    "        max_param=np.concatenate((max_heights,max_centers,max_hwhms))\n",
    "    \n",
    "        #actual fitting\n",
    "        x=FTIR['Ts']\n",
    "        popt,pcov=curve_fit(func,x,FTIR[gas],p0=init_guess,bounds=(min_param,max_param))\n",
    "        \n",
    "        #return values\n",
    "        for i in range(num_curves):\n",
    "            group=labels[gas][i]+'_'+gas.upper()\n",
    "            peaks['height'][group]=popt[i]\n",
    "            peaks['center'][group]=popt[i+num_curves]\n",
    "            peaks['hwhm'][group]=popt[i+2*num_curves]\n",
    "            if y_axis=='orig':\n",
    "                peaks['area'][group]=np.sum(gaussian(x,popt[i],popt[i+num_curves],popt[i+2*num_curves]))\n",
    "                peaks['mmol'][group]=peaks['area'][group]/tot_area*tot_mol\n",
    "                peaks['mmol_per_g'][group]=peaks['mmol'][group]*1000/TG_IR.info['dry_mass']#np.power(2*np.pi,0.5)*peaks['height'][labels[gas][i]+'('+gas+')']*peaks['hwhm'][labels[gas][i]+'('+gas+')']/(np.power(2*np.log(2),0.5))\n",
    "            elif y_axis=='rel':\n",
    "                peaks['mmol'][group]=peaks['area'][group]/tot_area*tot_mol\n",
    "                peaks['mmol_per_g'][group]=peaks['mmol'][group]*1000/TG_IR.info['dry_mass']\n",
    "        ###plotting\n",
    "        \n",
    "        profiles=pd.DataFrame()\n",
    "        data=FTIR[gas]\n",
    "        fit=multi_gauss(x,*popt)\n",
    "        diff=data-fit\n",
    "        sumsqerr[gas][TG_IR.info['name']]=np.sum(np.power(diff,2))\n",
    "        profiles['Ts']=x\n",
    "        profiles['data']=data\n",
    "        profiles['fit']=fit\n",
    "        profiles['diff']=diff\n",
    "            \n",
    "        if plot==True:\n",
    "            #setup plot\n",
    "            fig=plt.figure(constrained_layout=True)\n",
    "            gs = fig.add_gridspec(8, 1)\n",
    "            fitting = fig.add_subplot(gs[:-1, 0])\n",
    "            fitting.set_title('{} - {}, {} mg'.format(get_label(TG_IR.info['sample']),TG_IR.info['run'],TG_IR.info['mass']))\n",
    "            error = fig.add_subplot(gs[-1,0],sharex=fitting)\n",
    "            fitting.xaxis.set_ticks(np.arange(0, 1000, 50))\n",
    "            \n",
    "            #plotting of fit\n",
    "            fitting.plot(x,data,label='data',lw=2,zorder=num_curves+1)#,ls='',marker='x',markevery=2,c='cyan')\n",
    "            fitting.plot(x,fit,label='fit',lw=2,zorder=num_curves+2)\n",
    "        for i in range(0,num_curves):\n",
    "            y=gaussian(x,popt[i],popt[i+num_curves],popt[i+2*num_curves])\n",
    "            profiles[labels[gas][i]]=y\n",
    "            if plot==True:\n",
    "                fitting.text(popt[num_curves+i],popt[i],labels[gas][i],zorder=num_curves+3+i)\n",
    "                fitting.plot(x,y,linestyle='dashed',zorder=i)\n",
    "        if plot==True:\n",
    "            fitting.legend()\n",
    "            fitting.set_xlabel('T /째C')\n",
    "            if y_axis=='orig':\n",
    "                fitting.set_ylabel('{} /AU'.format(get_label(gas)))\n",
    "            elif y_axis=='rel':\n",
    "                fitting.set_ylabel('{} /mmol/g/s'.format(get_label(gas)))\n",
    "\n",
    "            #mark center on x-axis\n",
    "            fitting.scatter(popt[num_curves:2*num_curves],np.zeros(num_curves),marker=7,color='k',s=100,zorder=num_curves+3)\n",
    "\n",
    "            #plotting of absolute difference\n",
    "            abs_max=0.05*max(data)\n",
    "            \n",
    "            error.text(0,abs_max,'SQERR: {:.2e}'.format(sumsqerr[gas][TG_IR.info['name']]))#,'SQERR: '+'%.2E'% Decimal(sumsqerr[gas][TG_IR.info['name']]),va='bottom')\n",
    "            error.plot(x,diff)\n",
    "            error.hlines(0,min(x),max(x),ls='dashed')\n",
    "            error.set_xlabel('T /째C')\n",
    "            error.set_ylabel('error')#('AU')\n",
    "            error.set_ylim(-abs_max,abs_max)\n",
    "            plt.show()\n",
    "            fig.savefig(TG_IR.info['name']+'_'+gas+'.png', bbox_inches='tight', dpi=300)\n",
    "        if save==True:\n",
    "            try:\n",
    "                with pd.ExcelWriter(TG_IR.info['name']+y_axis+'.xlsx',engine='openpyxl', mode='a') as writer:\n",
    "                    profiles.to_excel(writer,sheet_name=gas)\n",
    "                    params.to_excel(writer,sheet_name=gas+'_param')\n",
    "            except:\n",
    "                with pd.ExcelWriter(TG_IR.info['name']+y_axis+'.xlsx',engine='openpyxl') as writer:\n",
    "                    profiles.to_excel(writer,sheet_name=gas)\n",
    "                    params.to_excel(writer,sheet_name=gas+'_param')\n",
    "    if save==True:                \n",
    "        with pd.ExcelWriter(TG_IR.info['name']+y_axis+'.xlsx',engine='openpyxl', mode='a') as writer:\n",
    "                peaks.astype(float).to_excel(writer,sheet_name='summary')\n",
    "    return peaks.astype(float),sumsqerr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```class TG_IR``` combines all functions in an object.\n",
    "\n",
    "```TG_IR('name')``` Initializes the object loads the data from TGA and FTIR with given 'name'. \n",
    "\n",
    "```.corr('reference')``` Corrects the loaded data with a given 'reference' measurement.\n",
    "\n",
    "```.plot(args)```   Visualizes the loaded data in different ways.\n",
    "\n",
    "```.fit(args)``` Deconvolutes the data and quantifies the amount of SOG with uncertainties.\n",
    "\n",
    "```.save()``` Saves the object as a pickle file. The file can be reloaded with ```load_TG_IR('name')```.\n",
    "\n",
    "Data from multiple objects can be visualized in a common graph wit ```plots(*objs,args)```.\n",
    "\n",
    "To perform the deconvolution procedure on multiple samples and summarize the data ```fits(*objs,args)``` can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class TG_IR:\n",
    "    linreg,stats = calibrate(sample_list='Kali_neu')\n",
    "    window_length=201\n",
    "    polyorder=3\n",
    "    def __init__(self,name,profile='Otto'):\n",
    "        try:\n",
    "            self.tga, self.info=read_TGA(name,profile=profile)\n",
    "            self.info['dry_mass']=self.info['mass']\n",
    "            self.tga['dtg']=-sp.signal.savgol_filter(self.tga['mass'],self.window_length,self.polyorder,deriv=1)\n",
    "        except:\n",
    "            print('No TG data for '+name+' was found')\n",
    "        \n",
    "        try:\n",
    "            self.ir=read_FTIR(name)\n",
    "            self.gases=self.ir.columns[1:]\n",
    "        except:\n",
    "            print('No IR data for '+name+' was found')\n",
    "        try:\n",
    "            self.ir=pd.merge(self.tga.filter(['t','Ts'],axis=1),self.ir, how='left',on='t').dropna(axis=0)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    def corr(self,baseline,which='both',plot=False):\n",
    "        self.info['baseline']=baseline\n",
    "\n",
    "        if which == 'both':\n",
    "            self.tga=corr_TGA(self.tga,baseline,plot=plot)\n",
    "            self.ir=corr_FTIR(self.ir,baseline,plot=plot)\n",
    "            self.tga['dtg']=-sp.signal.savgol_filter(self.tga['mass'],self.window_length,self.polyorder,deriv=1)\n",
    "            \n",
    "        elif which == 'IR':\n",
    "            self.ir=corr_FTIR(self.ir,baseline,plot=plot)\n",
    "            \n",
    "        elif which == 'TGA':\n",
    "            self.tga=corr_TGA(self.tga,baseline,plot=plot)\n",
    "            self.tga['dtg']=-sp.signal.savgol_filter(self.tga['mass'],self.window_length,self.polyorder,deriv=1)\n",
    "            \n",
    "        if which == 'both' or 'TGA':\n",
    "            try:\n",
    "                self.info.update(dry_weight(self,plot=plot))\n",
    "            except:\n",
    "                print('>> Trocknungsdaten konnten nicht erzeugt werden!')\n",
    "                \n",
    "                \n",
    "    def plot(self,which,x_axis='Ts',y_axis='orig',gases=[],save=False):\n",
    "        if which=='IR':\n",
    "            plot_FTIR(self,x_axis=x_axis,y_axis=y_axis,gases=gases,save=save)\n",
    "        \n",
    "        if which=='DIR':\n",
    "            temp=copy.deepcopy(self)\n",
    "            temp.ir.update(self.ir.filter(self.gases,axis=1).diff().ewm(span = 10).mean())\n",
    "            plot_FTIR(temp,x_axis=x_axis,y_axis=y_axis,gases=gases,save=save)\n",
    "            \n",
    "        if which=='D2IR':\n",
    "            temp=copy.deepcopy(self)\n",
    "            temp.ir.update(self.ir.filter(self.gases,axis=1).diff().diff().ewm(span = 20).mean())\n",
    "            plot_FTIR(temp,x_axis=x_axis,y_axis=y_axis,gases=gases,save=save)\n",
    "            \n",
    "        if which=='TG':\n",
    "            plot_TGA(self,'mass',x_axis=x_axis,y_axis=y_axis,save=save)\n",
    "            \n",
    "        if which=='heat_flow':\n",
    "            plot_TGA(self,which,x_axis=x_axis,y_axis=y_axis,save=save)\n",
    "            \n",
    "        if which=='IR_to_DTG':\n",
    "            FTIR_to_DTG(self,x_axis=x_axis,save=save,gases=gases)\n",
    "        \n",
    "        if which=='cumsum':\n",
    "            temp=copy.deepcopy(self)\n",
    "            temp.ir.update(self.ir.filter(self.gases,axis=1).cumsum())\n",
    "            plot_FTIR(temp,x_axis=x_axis,y_axis=y_axis,gases=gases,save=save)\n",
    "        \n",
    "    def fit(self,reference,tol_c=25,tol_hwhm=75,T_max=None,plot=True,func=multi_gauss,y_axis='orig',save=True):\n",
    "        if T_max==None:\n",
    "            T_max=max(self.tga['Ts'])\n",
    "        elif T_max>max(self.tga['Ts']):\n",
    "            print('$T_{max}$ exceeds maximum temperature of data')\n",
    "            T_max=max(self.tga['Ts'])\n",
    "            \n",
    "        ###extracting initial values for fitting from reference\n",
    "        references=pd.read_excel(os.path.join(dir_parameters,'surfgr_C.xlsx'),index_col=0,header=None)\n",
    "        init_params=references.loc[['gas',reference]].dropna(axis=1)\n",
    "\n",
    "        #find needed gases\n",
    "        gases=list(set(init_params.loc['gas']))\n",
    "\n",
    "        #initial center\n",
    "        temps=pd.DataFrame(columns=gases,index=range(len(init_params.columns)))\n",
    "        \n",
    "        #labels for the center\n",
    "        labels=pd.DataFrame(columns=gases,index=range(len(init_params.columns)))\n",
    "        for column in init_params.columns:\n",
    "            temps[init_params[column]['gas']][temps[init_params[column]['gas']].count()]=init_params[column][reference]\n",
    "            labels[init_params[column]['gas']][labels[init_params[column]['gas']].count()]=references[column]['group']\n",
    "        temps=temps.where(temps<T_max+tol_hwhm).dropna(thresh=1)\n",
    "        labels=labels.where(temps<T_max+tol_hwhm).dropna(thresh=1)\n",
    "        \n",
    "        if save==True:\n",
    "            path=os.path.join(dir_fits,time()+reference+'_'+self.info['name'])\n",
    "            os.mkdir(path)\n",
    "            os.chdir(path)\n",
    "            \n",
    "        temp=copy.deepcopy(self)\n",
    "        temp.tga=temp.tga[temp.tga['Ts']<T_max]\n",
    "        temp.ir=temp.ir[temp.ir['Ts']<T_max]\n",
    "        peaks, sumsqerr=fitting(temp,temps,labels,func,tol_center=tol_c,max_hwhm=tol_hwhm,plot=plot,y_axis=y_axis,save=save)\n",
    "        \n",
    "        os.chdir(home)\n",
    "        return peaks, sumsqerr\n",
    "    \n",
    "    def save(self):\n",
    "        with open(os.path.join(dir_output,self.info['name']+'.pkl'),'wb') as output:\n",
    "            pickle.dump(self,output,pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def plots(*TG_IR,plot,x_axis='Ts',y_axis='orig',gas=None,save=False):\n",
    "    fig=plt.figure()\n",
    "    #out=pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    if x_axis=='t':\n",
    "        plt.xlabel('t /s')\n",
    "    elif x_axis=='Ts':\n",
    "        plt.xlabel('T /째C')\n",
    "    \n",
    "    if plot=='TG':\n",
    "        if y_axis=='orig':\n",
    "            plt.ylabel('mass /mg')\n",
    "        if y_axis=='rel':\n",
    "            plt.ylabel('rel mass /%DM')\n",
    "            \n",
    "    if plot=='heat flow':\n",
    "        if y_axis=='orig':\n",
    "            plt.ylabel('heat flow /mW')\n",
    "        if y_axis=='rel':\n",
    "            plt.ylabel('heat flow /mWmg^{-1}')\n",
    "            \n",
    "    elif plot=='IR':\n",
    "        if gas==None:\n",
    "            gas=TG_IR[0].gases[0]\n",
    "        if y_axis=='orig':\n",
    "            plt.ylabel('{} /AU'.format(get_label(gas)))\n",
    "        if y_axis=='rel':\n",
    "            plt.ylabel('{} $/mmol g^{{-1}}s^{{-1}}$'.format(get_label(gas)))\n",
    "            \n",
    "    for obj in TG_IR:\n",
    "        if plot=='TG':\n",
    "            x=obj.tga[x_axis]\n",
    "            if y_axis=='orig':\n",
    "                y=obj.tga['mass']\n",
    "            elif y_axis=='rel':\n",
    "                y=obj.tga['mass']/obj.info['dry_mass']\n",
    "            plt.plot(x,y,label=get_label(obj.info['sample'])+' - '+obj.info['run'])\n",
    "        if plot=='heat flow':\n",
    "            x=obj.tga[x_axis]\n",
    "            if y_axis=='orig':\n",
    "                y=obj.tga['heat_flow']\n",
    "            elif y_axis=='rel':\n",
    "                y=obj.tga['heat_flow']/obj.info['dry_mass']\n",
    "            plt.plot(x,y,label=get_label(obj.info['sample'])+' - '+obj.info['run'])\n",
    "        if plot=='IR':\n",
    "            x=obj.ir[x_axis]\n",
    "            if y_axis=='orig':\n",
    "                y=obj.ir[gas]\n",
    "                plt.plot(x,y,label=get_label(obj.info['sample'])+' - '+obj.info['run'])#+', dry mass: '+str(round(obj.info['dry_mass'],2))+' mg'\n",
    "            elif y_axis=='rel':\n",
    "                y=1000*obj.ir[gas]/obj.linreg['slope'][gas]/obj.info['dry_mass']*10/(obj.info['method_value'][obj.info['method_param'].index('gradient')])          \n",
    "                plt.plot(x,y,label=r'{} - {}, {:.2f} mg'.format(get_label(obj.info['sample']),obj.info['run'],obj.info['mass']))\n",
    "            \n",
    "        \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    if save==True:\n",
    "        fig.savefig(os.path.join(dir_plots,'_'.join(list(set([str(obj.info['sample']) for obj in TG_IR]))+[plot,gas,y_axis])+'.png'), bbox_inches='tight', dpi=300)\n",
    "        \n",
    "\n",
    "def fits(*TG_IR,reference=None,tol_c=30,tol_hwhm=95,T_max=None,plot=True,y_axis='orig',init_offs=[0,0,0],save=True,labels=None,temps=None):\n",
    "    if reference!=None:\n",
    "        references=pd.read_excel(os.path.join(dir_parameters,'surfgr_C.xlsx'),index_col=0,header=None)\n",
    "        if T_max==None:\n",
    "            T_max=min([max(obj.tga['Ts']) for obj in TG_IR])\n",
    "\n",
    "        elif T_max>min([max(obj.tga['Ts']) for obj in TG_IR]):\n",
    "            T_max=T_max=min([max(obj.tga['Ts']) for obj in TG_IR])\n",
    "            print('$T_{max}$ exceeds maximum temperature of data')\n",
    "\n",
    "\n",
    "        init_params=references.loc[['gas',reference]].dropna(axis=1)\n",
    "        #find needed gases\n",
    "        gases=list(set(init_params.loc['gas']))\n",
    "\n",
    "        ###extracting initial values for fitting from reference\n",
    "        #initial center\n",
    "        temps=pd.DataFrame(columns=gases,index=range(len(init_params.columns)))\n",
    "        #labels for the center\n",
    "        labels=pd.DataFrame(columns=gases,index=range(len(init_params.columns)))\n",
    "        for column in init_params.columns:\n",
    "            temps[init_params[column]['gas']][temps[init_params[column]['gas']].count()]=init_params[column][reference]\n",
    "            labels[init_params[column]['gas']][labels[init_params[column]['gas']].count()]=references[column]['group'] \n",
    "        temps=temps.where(temps<T_max+tol_hwhm).dropna(thresh=1)\n",
    "        labels=labels.where(temps<T_max+tol_hwhm).dropna(thresh=1)\n",
    "\n",
    "    else:\n",
    "        gases=labels.columns\n",
    "    \n",
    "    #initializing of output DataFrames\n",
    "    col_labels=[group+'_'+gas.upper() for gas in gases for group in labels[gas].dropna()]+[gas.upper() for gas in gases]\n",
    "    err=pd.DataFrame(columns=gases)\n",
    "    names=['center','height','hwhm','area','mmol','mmol_per_g']\n",
    "    res=dict()\n",
    "    for name in names:\n",
    "        res[name]=pd.DataFrame(columns=col_labels)\n",
    "    \n",
    "    #make subdirectory to save data\n",
    "    if save==True:\n",
    "        path=os.path.join(dir_fits,time()+reference+'_'+'_'.join(list(set([str(obj.info['sample']) for obj in TG_IR]))))\n",
    "        os.mkdir(path)\n",
    "        os.chdir(path)\n",
    "    \n",
    "    #cycling through samples\n",
    "    for obj in TG_IR:\n",
    "        #fitting of the sample and calculating the amount of functional groups\n",
    "        if T_max!=None:\n",
    "            temp=copy.deepcopy(obj)\n",
    "            temp.tga=temp.tga[temp.tga['Ts']<T_max]\n",
    "            temp.ir=temp.ir[temp.ir['Ts']<T_max]\n",
    "        else:\n",
    "            temp=obj\n",
    "        peaks,sumsqerr=fitting(temp,temps,labels,multi_gauss,tol_center=tol_c,max_hwhm=tol_hwhm,plot=plot,y_axis=y_axis,save=save,init_offs=init_offs)\n",
    "\n",
    "        #writing data to output DataFrames\n",
    "        for key in res:\n",
    "            res[key]=res[key].append(peaks[key].rename(obj.info['name']).T)  \n",
    "        err=err.append(sumsqerr)\n",
    "\n",
    "    # calculate statistical values\n",
    "    dm=1e-6\n",
    "    for key in res:\n",
    "        samples=list(set([get_label(re.search('(?<=_)\\d{5}(?=_\\d{2,3})',index).group()) for index in res[key].index]))\n",
    "        stddev=pd.DataFrame(columns=res[key].columns,index=[sample+'_stddev' for sample in samples])\n",
    "        mean=pd.DataFrame(columns=res[key].columns,index=[sample+'_mean' for sample in samples])\n",
    "        for sample in samples:\n",
    "            for column in res[key].columns:\n",
    "                gas=column[column.rfind('_')+1:].lower()\n",
    "                indices=[index for index in res[key].index if get_label(re.search('(?<=_)\\d{5}(?=_\\d{2,3})',index).group())==sample]\n",
    "                subset=res[key][column].loc[indices]\n",
    "                if key=='mmol_per_g':\n",
    "                    mmol=res['mmol'][gas.upper()].loc[indices]#res['mmol'][column].loc[indices]\n",
    "                    g=mmol/subset\n",
    "                    lod=TG_IR[0].stats['x_NG'][gas]\n",
    "                    dmmolg_i=np.power(np.power(lod/mmol,2)+np.power(dm/g,2),0.5)*subset\n",
    "                    dmmol=np.power(np.sum(np.power(dmmolg_i,2)),0.5)\n",
    "                    stddev[column][sample+'_stddev']=dmmol\n",
    "                else:\n",
    "                    stddev[column][sample+'_stddev']=np.std(subset)\n",
    "                mean[column][sample+'_mean']=np.mean(subset)\n",
    "        res[key]=res[key].append(mean)\n",
    "        res[key]=res[key].append(stddev)        \n",
    "    \n",
    "    #exporting data\n",
    "    if save==True:\n",
    "        with pd.ExcelWriter('summary.xlsx') as writer:\n",
    "            for key in res:\n",
    "                res[key].dropna(axis=1).to_excel(writer,sheet_name=key)\n",
    "            err.to_excel(writer,sheet_name='sum_squerr')\n",
    "        os.chdir(home)\n",
    "    return res\n",
    "\n",
    "def read_TG_IR(name):\n",
    "    with open(os.path.join(dir_output,name+'.pkl'), 'rb') as inp:\n",
    "        obj = pickle.load(inp)\n",
    "    return obj"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
